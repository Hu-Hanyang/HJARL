diff --git a/WorkingLogs.md b/WorkingLogs.md
index e4beb62..6322b21 100644
--- a/WorkingLogs.md
+++ b/WorkingLogs.md
@@ -87,6 +87,15 @@ python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrot
 python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_boltz --algo ppo --task quadrotor_fixed --test_distb_level 1.0 --seed 2024
 python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_null --algo ppo --task quadrotor_fixed --test_distb_level 1.0  --seed 42
 
-## Env Info
+### test in the quadrotor_wind
+python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_boltz --algo ppo --task quadrotor_wind --seed 2024
+python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_null --algo ppo --task quadrotor_wind --seed 42
+
+### test in the quadrotor_random_hj
+python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_boltz --algo ppo --task quadrotor_randomhj --seed 2024
+python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_null --algo ppo --task quadrotor_randomhj --seed 42
+python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_null --algo rarl --task quadrotor_randomhj  --seed 42
 
+
+## Env Info
 python safe_control_gym/experiments/test_rl_controller.py --trained_task quadrotor_boltz --algo ppo --task quadrotor_random --seed 42  --render
diff --git a/safe_control_gym/envs/__init__.py b/safe_control_gym/envs/__init__.py
index 7a1345b..a1a6e06 100644
--- a/safe_control_gym/envs/__init__.py
+++ b/safe_control_gym/envs/__init__.py
@@ -63,6 +63,10 @@ register(idx='quadrotor_randomhj',
          entry_point='safe_control_gym.envs.gym_pybullet_drones.quadrotor_distb:QuadrotorRandomHJDistb',
          config_entry_point='safe_control_gym.envs.gym_pybullet_drones:quadrotor_distb.yaml')
 
+register(idx='quadrotor_wind',
+         entry_point='safe_control_gym.envs.gym_pybullet_drones.quadrotor_distb:QuadrotorWindDistb',
+         config_entry_point='safe_control_gym.envs.gym_pybullet_drones:quadrotor_distb.yaml')
+
 register(idx='reach_avoid',
          entry_point='safe_control_gym.envs.gym_game.ReachAvoidGame:ReachAvoidGameEnv')
 
diff --git a/safe_control_gym/envs/gym_pybullet_drones/base_distb_aviary.py b/safe_control_gym/envs/gym_pybullet_drones/base_distb_aviary.py
index 61367d8..cea448b 100644
--- a/safe_control_gym/envs/gym_pybullet_drones/base_distb_aviary.py
+++ b/safe_control_gym/envs/gym_pybullet_drones/base_distb_aviary.py
@@ -161,7 +161,7 @@ class BaseDistbAviary(BenchmarkEnv):
         # Hanyang: initialize the disturbance parameters and the initial state randomization parameters here.
         self.distb_type = distb_type
         self.distb_level = distb_level
-        assert self.distb_type in ['fixed', 'boltzmann', 'random_hj', 'random', None], f"[ERROR] The disturbance type '{self.distb_type}' is not supported now. \n"
+        assert self.distb_type in ['fixed', 'boltzmann', 'random_hj', 'random', 'wind', None], f"[ERROR] The disturbance type '{self.distb_type}' is not supported now. \n"
         self.init_xy_lim = 0.25
         self.init_z_lim = 0.1
         self.init_rp_lim = np.pi/6
@@ -364,12 +364,15 @@ class BaseDistbAviary(BenchmarkEnv):
                     high = np.array([6e-3, 6e-3, 1.5e-4])
                     # Generate a random sample
                     hj_distbs = np.random.uniform(low, high)
+                elif self.distb_type == 'wind':  # contant wind disturbances
+                    hj_distbs = np.array([0.0, 0.0037099999999999998, 0.0])
+                    # print(f"[INFO] The disturbance in the wind distb is {hj_distbs}. \n")
                 else: # HJ based fixed, random_hj or boltzmann disturbances
                     current_angles = quat2euler(self._get_drone_state_vector(i)[3:7])  # convert quaternion to eulers
                     current_angle_rates = self._get_drone_state_vector(i)[13:16]
                     current_state = np.concatenate((current_angles, current_angle_rates), axis=0)
                     _, hj_distbs = distur_gener_quadrotor(current_state, self.distb_level)
-                    print(f"[INFO] The disturbance for drone {i} is {hj_distbs}. \n")
+                    # print(f"[INFO] The disturbance for drone {i} is {hj_distbs}. \n")
                 
                 if self.PHYSICS == Physics.PYB:
                     # self._physics(clipped_action[i, :], i)
diff --git a/safe_control_gym/envs/gym_pybullet_drones/quadrotor_distb.py b/safe_control_gym/envs/gym_pybullet_drones/quadrotor_distb.py
index 0940a45..4ae05e6 100644
--- a/safe_control_gym/envs/gym_pybullet_drones/quadrotor_distb.py
+++ b/safe_control_gym/envs/gym_pybullet_drones/quadrotor_distb.py
@@ -757,3 +757,18 @@ class QuadrotorRandomDistb(QuadrotorDistb):
         kwargs['seed'] = 2024
         kwargs['adversary_disturbance'] = 'dynamics'  # TODO: for rarl test, but not sure whether it has influences on the performances or not
         super().__init__(*args, **kwargs)  # distb_level=distb_level, randomization_reset=randomization_reset,
+
+
+class QuadrotorWindDistb(QuadrotorDistb):
+    NAME = 'quadrotor_wind'
+    #TODO: Hanyang: add contant wind torque disturbance
+    # Hanyang: add contant wind torque disturbance
+    def __init__(self, *args,  **kwargs):  # distb_level=1.0, randomization_reset=False,
+        # Set disturbance_type to 'fixed' regardless of the input
+        kwargs['distb_type'] = 'wind'
+        kwargs['distb_level'] = 0.0
+        kwargs['randomized_init'] = True
+        kwargs['record'] = False
+        kwargs['seed'] = 2024
+        kwargs['adversary_disturbance'] = 'dynamics'  # TODO: for rarl test, but not sure whether it has influences on the performances or not
+        super().__init__(*args, **kwargs)  # distb_level=distb_level, randomization_reset=randomization_reset,
diff --git a/safe_control_gym/experiments/test_game1.py b/safe_control_gym/experiments/test_game1.py
index 96263d5..c6072af 100644
--- a/safe_control_gym/experiments/test_game1.py
+++ b/safe_control_gym/experiments/test_game1.py
@@ -182,6 +182,7 @@ if __name__ == "__main__":
     args.exp_name = "train_game.cleanrl_model"
     run_name = os.path.join('training_results/' + 'game/ppo/' +f'{args.seed}/' + f'{args.total_timesteps}' )
     model_path = f"{run_name}/{args.exp_name}"
+    print(f"The loaded model is {model_path}. \n")
     assert os.path.exists(model_path), f"Model path {model_path} does not exist."
     
     episodic_returns, envs = evaluate(
diff --git a/safe_control_gym/experiments/train_game.py b/safe_control_gym/experiments/train_game.py
index f59782e..3cf1fc6 100644
--- a/safe_control_gym/experiments/train_game.py
+++ b/safe_control_gym/experiments/train_game.py
@@ -45,7 +45,7 @@ class Args:
     # Algorithm specific arguments
     env_id: str = "reach_avoid"
     """the id of the environment"""
-    total_timesteps: int = 1e7
+    total_timesteps: int = 2e7
     """total timesteps of the experiments"""
     learning_rate: float = 3e-4
     """the learning rate of the optimizer"""
diff --git a/wandb/latest-run b/wandb/latest-run
index 5633679..6eb3ab1 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20240620_175922-j13jmons
\ No newline at end of file
+run-20240622_093244-xrlwdxiv
\ No newline at end of file
