algo: ppo
algo_config:
  activation: leaky_relu
  actor_lr: 0.0007948148615930024
  clip_obs: 10
  clip_param: 0.1
  clip_reward: 10
  critic_lr: 0.007497368468753617
  deque_size: 10
  entropy_coef: 0.00010753631441212628
  eval_batch_size: 10
  eval_interval: 1000
  eval_save_best: true
  gae_lambda: 0.8
  gamma: 0.98
  hidden_dim: 32
  log_interval: 10
  max_ctrl_steps: 250
  max_env_steps: 72000
  max_grad_norm: 0.5
  mini_batch_size: 128
  norm_obs: false
  norm_reward: false
  num_checkpoints: 10
  num_workers: 1
  opt_epochs: 5
  render_height: 400
  render_width: 640
  rollout_batch_size: 4
  rollout_steps: 150
  save_interval: 1000
  target_kl: 1.587713889686473e-07
  tensorboard: true
  training: true
  use_clipped_value: false
  use_gae: false
device: cuda
distb_level: 1.0
env_distb_level: 0.0
env_distb_type: fixed
output_dir: training_results/cartpole_null/ppo/seed_42/72000steps
restore: null
seed: 42
tag: temp
task: cartpole_null
task_config:
  adversary_disturbance: dynamics
  adversary_disturbance_offset: 0.0
  adversary_disturbance_scale: 0.01
  constraint_penalty: -1
  constraints: null
  cost: rl_reward
  ctrl_freq: 50
  disturbances: null
  done_on_out_of_bound: true
  done_on_violation: false
  episode_len_sec: 5
  gui: false
  inertial_prop: null
  inertial_prop_randomization_info: null
  info_in_reset: true
  init_state: null
  init_state_randomization_info: null
  normalized_rl_action_space: false
  obs_goal_horizon: 0
  obs_wrap_angle: false
  pyb_freq: 50
  randomized_inertial_prop: false
  randomized_init: true
  render_height: 400
  render_width: 640
  rew_act_weight: 0.0001
  rew_exponential: true
  rew_state_weight: 1.0
  task: stabilization
  task_info: null
  use_constraint_penalty: false
  verbose: false
use_gpu: true
